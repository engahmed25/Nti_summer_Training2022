{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f079f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # tested with 1.14.0\n",
    "import numpy as np # tested with 1.16.4\n",
    "import matplotlib.pyplot as plt #tested with 3.0.3\n",
    "from sklearn.metrics import classification_report # tested with 0.21.2l\n",
    "import keras\n",
    "# Supress deprecation warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# Fetch \"Fashion MNIST\" data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# A good rule of thumb is to normalise input values - i.e. transform them to a\n",
    "# scale of 0 to 1. Each element in this dataset is a pixel value of 0 to 255, so\n",
    "# we'll normalise / rescale these values.\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Map for human readable class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e58a94b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Image Data: (60000, 28, 28)\n",
      "Shape of Training Class Data: (60000,)\n",
      "Shape of Test Image Data: (10000, 28, 28)\n",
      "Shape of Test Class Data: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training Image Data: \" + str(x_train.shape))\n",
    "print(\"Shape of Training Class Data: \" + str(y_train.shape))\n",
    "print(\"Shape of Test Image Data: \" + str(x_test.shape))\n",
    "print(\"Shape of Test Class Data: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ca193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\",\n",
    "                              input_shape=(28,28,1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17c6e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(keras.layers.Dropout(rate=.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=128,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=10,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abeb5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a77f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               692352    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "519e6819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 25s 128ms/step - loss: 0.5373 - accuracy: 0.8147 - val_loss: 0.3686 - val_accuracy: 0.8717\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 22s 118ms/step - loss: 0.3442 - accuracy: 0.8801 - val_loss: 0.3350 - val_accuracy: 0.8830\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 22s 117ms/step - loss: 0.3041 - accuracy: 0.8924 - val_loss: 0.3006 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 21s 110ms/step - loss: 0.2783 - accuracy: 0.9014 - val_loss: 0.2885 - val_accuracy: 0.8967\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 21s 112ms/step - loss: 0.2599 - accuracy: 0.9067 - val_loss: 0.2716 - val_accuracy: 0.9040\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.2438 - accuracy: 0.9115 - val_loss: 0.2567 - val_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 20s 108ms/step - loss: 0.2284 - accuracy: 0.9169 - val_loss: 0.2614 - val_accuracy: 0.9052\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.2169 - accuracy: 0.9216 - val_loss: 0.2492 - val_accuracy: 0.9097\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 23s 125ms/step - loss: 0.2079 - accuracy: 0.9244 - val_loss: 0.2538 - val_accuracy: 0.9098\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 21s 113ms/step - loss: 0.1981 - accuracy: 0.9276 - val_loss: 0.2555 - val_accuracy: 0.9078\n"
     ]
    }
   ],
   "source": [
    "# Add an empty color dimension as the Convolutional net is expecting this\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Train the CNN on the training data\n",
    "history = model.fit(\n",
    "    \n",
    "      # Training data : features (images) and classes.\n",
    "      x_train, y_train,\n",
    "                    \n",
    "      # number of samples to work through before updating the \n",
    "      # internal model parameters via back propagation.\n",
    "      batch_size=256, \n",
    "\n",
    "      # An epoch is an iteration over the entire training data.\n",
    "      epochs=10, \n",
    "\n",
    "      # The model will set apart his fraction of the training \n",
    "      # data, will not train on it, and will evaluate the loss\n",
    "      # and any model metrics on this data at the end of \n",
    "      # each epoch. \n",
    "      validation_split=0.2, \n",
    "\n",
    "      verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962a0c0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7436/1254252619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get Model Predictions for test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# Get Model Predictions for test data\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an empty color dimension as the Convolutional net is expecting this\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Train the CNN on the training data\n",
    "history = model.fit(\n",
    "    \n",
    "      # Training data : features (images) and classes.\n",
    "      x_train, y_train,\n",
    "                    \n",
    "      # number of samples to work through before updating the \n",
    "      # internal model parameters via back propagation.\n",
    "      batch_size=256, \n",
    "\n",
    "      # An epoch is an iteration over the entire training data.\n",
    "      epochs=10, \n",
    "\n",
    "      # The model will set apart his fraction of the training \n",
    "      # data, will not train on it, and will evaluate the loss\n",
    "      # and any model metrics on this data at the end of \n",
    "      # each epoch. \n",
    "      validation_split=0.2, \n",
    "\n",
    "      verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a264b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(model.predict(x_test), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, \n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Add dropouts to the model\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59582299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
